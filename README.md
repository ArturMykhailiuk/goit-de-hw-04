# goit-de-hw-04
## 1.Результат виконання запиту з одним action'ом
![p1](https://github.com/user-attachments/assets/3d235ed3-9c0a-4ca1-a9dd-51185ef08668)
### Jobs:  
  0: Сканування даних;  
  1: Job 0 + Десеріалізація;  
  2: Репартиціонування;  
  3: Фільтрація.Групування.Підрахунок рядків;  
  4: Збирання результату.
  
## 2.Результат виконання запиту з додатковим action'ом
![p2](https://github.com/user-attachments/assets/90ede2f0-2598-4398-90c7-928d81f0595c)
  ### Jobs:  
  0: Сканування даних;  
  1: Job 0 + Десеріалізація;  
  2: Репартиціонування;  
  3: Фільтрація.Групування.Підрахунок рядків;  
  4: Проміжне збирання результату;  
  5: Репартиціонування;  
  6: Фільтрація;  
  7: Збирання результату.
  #### Висновок:    
  Після проміжного collect(), коли ми додали нову трансформацію where("count > 2"), Spark виконує попередні трансформації знову, якщо результат не був кешований.
  
  
## 3.Результат використання функції cached()
![p3](https://github.com/user-attachments/assets/afb68576-f1e2-4d2c-ac19-1f52a575caa4)
  ### Jobs:  
  0: Сканування даних;  
  1: Job 0 + Десеріалізація;  
  2: Репартиціонування;  
  3: Фільтрація.Групування.Підрахунок рядків.Кешування даних;  
  4: Проміжне збирання результату;  
  5: Фільтрація;  
  6: Збирання результату.
  #### Висновок:  
  Використання cache() у Spark дозволяє зберігати результат проміжних трансформацій у пам'яті, що дозволяє уникнути повторного виконання цих трансформацій при наступних діях. Це зменшує кількість джобів, оскільки Spark не потрібно повторно 
  виконувати ті ж самі трансформації


